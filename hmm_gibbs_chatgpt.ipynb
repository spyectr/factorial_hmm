{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt code for gibbs sampling\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def gibbs_sampling_hmm(observed_data, num_states, num_samples, burn_in):\n",
    "    # Initialize model parameters randomly\n",
    "    transition_probs = np.random.rand(num_states, num_states)\n",
    "    transition_probs /= np.sum(transition_probs, axis=1, keepdims=True)\n",
    "    emission_means = np.random.rand(num_states, observed_data.shape[1])\n",
    "    emission_variances = np.random.rand(num_states)\n",
    "    hidden_states = np.zeros(len(observed_data), dtype=int)\n",
    "    \n",
    "    # Run Gibbs sampler\n",
    "    for i in range(num_samples + burn_in):\n",
    "        # Sample hidden states given observed data and model parameters\n",
    "        for t in range(len(observed_data)):\n",
    "            if t == 0:\n",
    "                hidden_states[t] = np.random.randint(num_states)\n",
    "            else:\n",
    "                probs = transition_probs[hidden_states[t-1], :]\n",
    "                hidden_states[t] = np.random.choice(num_states, p=probs)\n",
    "        \n",
    "        # Update transition probabilities given hidden states\n",
    "        for s in range(num_states):\n",
    "            for s_next in range(num_states):\n",
    "                count = 0\n",
    "                for t in range(1, len(observed_data)):\n",
    "                    if hidden_states[t-1] == s and hidden_states[t] == s_next:\n",
    "                        count += 1\n",
    "                transition_probs[s, s_next] = np.random.beta(1 + count, 1 + np.sum(hidden_states[:-1] == s) - count)\n",
    "        \n",
    "        # Update emission parameters given hidden states and observed data\n",
    "        for s in range(num_states):\n",
    "            samples = observed_data[hidden_states == s, :]\n",
    "            mean = np.mean(samples, axis=0)\n",
    "            covariance = np.cov(samples.T)\n",
    "            emission_means[s] = np.random.multivariate_normal(mean, covariance / len(samples))\n",
    "            emission_variances[s] = np.random.gamma(len(samples) * observed_data.shape[1] / 2, 2 / np.sum((samples - mean)**2))\n",
    "        \n",
    "        # Store model parameters after burn-in period\n",
    "        if i >= burn_in:\n",
    "            yield (transition_probs, emission_means, emission_variances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gibbs_sampling_arhmm(observed_data, num_states, lag_order, num_samples, burn_in):\n",
    "    # Initialize model parameters randomly\n",
    "    transition_probs = np.random.rand(num_states, num_states)\n",
    "    transition_probs /= np.sum(transition_probs, axis=1, keepdims=True)\n",
    "    emission_weights = np.random.rand(observed_data.shape[1], num_states)\n",
    "    emission_variances = np.random.rand(observed_data.shape[1], num_states)\n",
    "    lag_weights = np.random.rand(observed_data.shape[1], num_states, lag_order)\n",
    "    hidden_states = np.zeros(len(observed_data), dtype=int)\n",
    "    \n",
    "    # Pad observed data with zeros to allow for lagged observations\n",
    "    padded_data = np.vstack([np.zeros((lag_order, observed_data.shape[1])), observed_data])\n",
    "    \n",
    "    # Run Gibbs sampler\n",
    "    for i in range(num_samples + burn_in):\n",
    "        # Sample hidden states given observed data and model parameters\n",
    "        for t in range(len(observed_data)):\n",
    "            if t == 0:\n",
    "                hidden_states[t] = np.random.randint(num_states)\n",
    "            else:\n",
    "                probs = transition_probs[hidden_states[t-1], :]\n",
    "                hidden_states[t] = np.random.choice(num_states, p=probs)\n",
    "        \n",
    "        # Update transition probabilities given hidden states\n",
    "        for s in range(num_states):\n",
    "            for s_next in range(num_states):\n",
    "                count = 0\n",
    "                for t in range(1, len(observed_data)):\n",
    "                    if hidden_states[t-1] == s and hidden_states[t] == s_next:\n",
    "                        count += 1\n",
    "                transition_probs[s, s_next] = np.random.beta(1 + count, 1 + np.sum(hidden_states[:-1] == s) - count)\n",
    "        \n",
    "        # Update emission weights, variances, and lag weights given hidden states and observed data\n",
    "        for s in range(num_states):\n",
    "            samples = observed_data[hidden_states == s, :]\n",
    "            for f in range(observed_data.shape[1]):\n",
    "                mean = np.mean(samples[:, f])\n",
    "                variance = np.var(samples[:, f])\n",
    "                emission_weights[f, s] = np.random.normal(mean, np.sqrt(variance / len(samples)))\n",
    "                emission_variances[f, s] = np.random.gamma(len(samples) / 2, 2 / np.sum((samples[:, f] - mean)**2))\n",
    "                for l in range(lag_order):\n",
    "                    lagged_samples = padded_data[l:len(observed_data)+l, :]\n",
    "                    lag_mean = np.mean(lagged_samples[hidden_states == s, f])\n",
    "                    lag_var = np.var(lagged_samples[hidden_states == s, f])\n",
    "                    lag_weights[f, s, l] = np.random.normal(lag_mean, np.sqrt(lag_var / len(lagged_samples)))\n",
    "        \n",
    "        # Store model parameters after burn-in period\n",
    "        if i >= burn_in:\n",
    "            yield (transition_probs, emission_weights, emission_variances, lag_weights)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
